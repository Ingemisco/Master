\section{Conclusions and Future Work}
\label{sec:discussion_conclusion}

We explored intricacies of the global Fréchet distance in depth and discussed multiple simplification algorithms. 
The implicit and semiexplicit approaches we have introduced present a new perspective on the computational model required to solve Fréchet distance related algorithms and are sufficient to show that square roots are not necessary in the Euclidean case. The resulting algorithms are competetive with the explicit versions albeit still slower.

Our discussion, implementations, and evaluation of \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance}'s algorithm showed that minimal optimizations make the algorithm highly performant while still being simple to implement. 

\citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal}'s algorithm inevitably becomes faster than the optimized \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance} algorithm however it has worse parallelizability. Thus the exact polyline length at which it becomes the faster algorithm is system dependent. 

The Chebyshev distance seems to be a practical alternative for the Euclidean distance as the runtimes for both algorithms differ only negligibly. The necessary solving algorithm is simple to implement and fast and unlike the explicit Euclidean variant does not require square roots thus making it more numerically stable. 

A surprising experimental result is that local and global simplifications do not differ at all in practice but only on artificially crafted counterexamples. As currently local simplification algorithms are much simpler to implement and faster than their global counterparts\footnote{In our implementations, the main logic of the Imai-Iri algorithm was implemented in around 50 lines of code while the simple algorithm took approximately 200 lines of code and the advanced one required around 300 lines of code. We have not reported on the runtime of the Imai-Iri algorithm as we are interested in global algorithms but according to our tests it was around 370 times faster.} this suggests that in practice global simplification is hardly useful. Positively interpreted, this means that local simplifications are in practice just as good as global ones. 

By exploring the size of simplifications we discovered that the well-behavedness of the polyline affects the simplification more than the distance used. This also implies that different types of distances share a common class of well-behaved polylines. 

We have developed an algorithm that finds all simplifications in \(\Oh(n^4\log n)\) runtime and \(\O(n^3)\) space. Using this we were able to explore the effect of the used \(\varepsilon\) on the simplification size. It seems that the size follows a rectangular hyperbola function.

Finally, our attempt at adapting the algorithm from \citeauthor{computational_geometric_methods_for_polygonal_approximations_of_a_curve} lead to an alternative, and in our optinion more visually intuitive, derivation of the algorithm from \citeauthor{global_curve_simplification}.

We conclude with open research questions and possibilities for future work that our thesis presents.

\begin{itemize}
  \item Is it possible to achieve subcubic runtime when using the global Fréchet distance for simplification?

	This is an open problem since \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal} discovered a cubic algorithm. For high dimensions this is likely not the case as they showed but for the more interesting two dimensional case nothing is currently known. In the local case this was answered already in the affermative.

	\item Is it possible to achieve subcubic space consumption when using the global Fréchet distance for simplification?

	All cubic runtime algorithms currently require cubic space consumption. Our tests of the algorithm from \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal} was finally stopped because of a lack of space so this is indeed a practical issue. \citeauthor{global_curve_simplification}'s algorithm can be implemented in quadratic space but incurs a logarithmic factor to the runtime but a cubic runtime algorithm with subcubic space consumption is currently not know.

	Note that a subcubic runtime algorithm also answers this question positively.

	\item Can \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance}'s algorithm with our optimizations be reanalyzed to achieve a better runtime? 

	Our tests show that our optimizations affect the runtime massively and make it competetive with the cubic runtime algorithm from \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal}. Experimental data makes it likely that subquintic runtime is already achieve if not subquartic. However, it almost certainly scales worse than cubically. 

	It may be possible to bound how often the optimizations are triggered and how many iterations are skipped on average to show lower runtime bounds but this involves a more sophisticated analysis of the algorithm's choices.

	\item Are there good approximation algorithms for global Fréchet simplification?

	This is an approach to achieve subcubic runtime and space consumption in the case that this is not possible for exact algorithms. As polyline simplifications are themselves just visual approximations it is reasonable to allow non-optimal simplifications that come with a guaranteed approximation factor.

	\item Can the algorithm from \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal} be parallelized?

	Due to parallelization the algorithm from \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance} is faster than this algorithm on small data. Using parallelization it could become the definitively better algorithm and improve simplification times for large polylines.
\end{itemize}


