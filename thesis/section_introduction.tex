\section{Introduction}
\label{sec:introduction}

Polyline simplification is the process of algorithmically reducing the number of points of a polyline while preserving its general shape up to a specified error parameter \(\varepsilon\). This technique is widely used in applications such as geographic information systems (GIS) to simplify map contours~\cite{algorithms_reduction_number_points_caricature}. To evaluate the quality of a simplification, distance functions between polylines are employed, with the Hausdorff and Fréchet distances being the most common. These distances can be applied either \emph{locally}, where each segment of the simplified polyline is compared with the corresponding subpolyline of the original, or \emph{globally}, where the entire simplification is compared to the original as a whole.

Local simplification has been extensively studied for both the Hausdorff and the Fréchet distances~\cite{polyline_simplification_under_the_local_frechet_distance_has_almost_quadratic_runtime_in_2d_storandtetal,computational_geometric_methods_for_polygonal_approximations_of_a_curve}. In contrast, global simplification has only recently gained attention. \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance} proposed a polynomial-time algorithm for global Fréchet simplification and proved that global Hausdorff simplification is NP-hard. Later, \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal} improved this result by developing a cubic-time algorithm and establishing conditional lower bounds for global Fréchet simplification as well as both local variants.

In this thesis, we provide a detailed discussion of these two algorithms, complete with examples. We explain every step, from solving the necessary equations to the full simplification algorithms, aiming to serve as a comprehensive guide for implementation. Furthermore, we present a wide array of optimizations to achieve better practical runtimes, including parallelization, compiler configuration, and hardware-specific considerations.

First, we define the terminology, definitions, and mathematical concepts used throughout this thesis in \cref{sec:preliminaries}. Then, in \cref{sec:preliminaries} we distinguish the more commonly used local variants from the global variants that are the focus of this work and derive simple properties to develop an intuition for working with the Fréchet distance.

Before discussing the simplification algorithms, we show how to solve various necessary equations in \cref{sec:equation_solving}, where we derive the formula for the Euclidean case and present algorithms for the Manhattan and Chebyshev cases. Following this, we explain the algorithm from \citeauthor{on_optimal_polyline_simplification_using_the_hausdorff_and_frechet_distance} for polyline simplification as well as the required algorithm from \citeauthor{computing_the_frechet_distance_between_two_polygonal_curves}. We visualize the algorithm with examples to build intuition and motivate applicable optimizations.

We continue more theoretically by proposing our implicit Fréchet framework in \cref{sec:implicit_polyline_simplification} and show how to transform current approaches, which we call explicit, into implicit ones using the examples of the previously discussed algorithms. The implicit approach relies on the fact that we never need to perform arithmetic on the solutions of equations from \cref{sec:equation_solving} but only comparisons. As a consequence, we show that in the Euclidean case, polyline simplification can be solved without square root and division operations while maintaining the same theoretical runtime. For general distances, the implicit approach is applicable and can potentially avoid the need to find roots of higher-order polynomials, though it requires solving problems in real algebraic geometry.

\cref{sec:cubic_algo} explains the algorithm from \citeauthor{polyline_simplification_has_cubic_complexity_bringmannetal} and the required cell reachability problem. Again, we explain the algorithms utilizing examples and mention practical considerations.

Having seen two algorithms to simplify a polyline for a single \(\varepsilon\), we present an algorithm that computes \emph{all} simplifications for a polyline in \cref{sec:simplification-queries}. For this, we determine the intervals in which the simplification size does not change. This allows the creation of a data structure that facilitates querying for simplifications given an \(\varepsilon\) in \(\O(\log n)\) time. The construction of this data structure relies on a deep analysis of the decisions made by the simplification algorithms. We show how to construct such a data structure in \(\Oh(n^4 \log n)\) time and \(\O(n^3)\) space. Interestingly, we show that this problem is much simpler in the Euclidean case than in the Manhattan or Chebyshev cases in multiple aspects, unlike the regular simplification algorithms which are largely distance-agnostic when treating the equation-solving algorithm as a black box.

In \cref{sec:global_imai_iri}, we address the problem of finding subcubic algorithms in two dimensions. In the local variants, this has been achieved by improving the algorithm from \citeauthor{computational_geometric_methods_for_polygonal_approximations_of_a_curve}. Using this as motivation, our goal is to adapt the same algorithm to the global variant to apply local techniques. The resulting algorithm is functionally equivalent to the one by \citeauthor{global_curve_simplification} but provides a more intuitive perspective on its underlying principles.

\cref{sec:evaluation} presents an extensive experimental evaluation of the implemented algorithms, which, to our knowledge, is the first for the global variants. We measure performance and simplification size while varying a multitude of parameters to demonstrate their effects.

Finally, we conclude with \cref{sec:discussion_conclusion} and mention possible future work.
 
